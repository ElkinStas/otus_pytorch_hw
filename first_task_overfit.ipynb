{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Подготовка датасета\n",
    "# Загрузить данные\n",
    "train = pd.read_csv(r\"./train.csv\",dtype = np.float32)\n",
    "\n",
    "# Разобьем данные на пиксели(features) и классы на которые будем делить(цифры от 0 до 9)\n",
    "targets_numpy = train.label.values\n",
    "features_numpy = train.loc[:,train.columns != \"label\"].values  # Нормализация\n",
    "\n",
    "#features_numpy2 = np.arraynp.random.rand(3,2)\n",
    "#features_numpy = features_numpy2 + features_numpy1\n",
    "# train test split.  Размер тестовый = 0.2, соответсвенно тренировочный будет 0.8. \n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.1,\n",
    "                                                                             random_state = 42) \n",
    "\n",
    "# Создадим feature и целевой тензор для тренировочного датасета.\n",
    "# Для того чтобы переменные могли аккумулировать градиенты, мы должны создать тензор в котором они будут хранится.\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) \n",
    "\n",
    "# Аналогично для тестового датасета.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)\n",
    "\n",
    "# batch_size == размер батча, epoch == количество эпох обучения и iteration == количество итераций\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Датасет в Pytorch \n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# создадим загрузчик данных в PyTorch - data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# Визуализируем одно из изображений\n",
    "plt.imshow(features_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание ANN модели\n",
    "class ANNModel(nn.Module):\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        \n",
    "        # Линейная функция 1: 784 --> 150\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1) \n",
    "        # Не линейная функция 1\n",
    "        self.relu1 = nn.Tanh()\n",
    "        \n",
    "        # Linear function 2: 150 --> 150\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        # Не линейная функция 2\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        \n",
    "        # Linear function 3: 150 --> 150\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        # Не линейная функция 3\n",
    "        self.elu3 = nn.Tanh()\n",
    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        # Не линейная функция 3\n",
    "        self.elu4 = nn.Tanh()\n",
    "        # Linear function 4 (readout): 150 --> 10\n",
    "        self.fc5 = nn.Linear(hidden_dim4, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Линейная функция 1\n",
    "        out = self.fc1(x)\n",
    "        # Не линейная функция 1\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Линейная функция 2\n",
    "        out = self.fc2(out)\n",
    "        # Не линейная функция 2\n",
    "        out = self.tanh2(out)\n",
    "        \n",
    "        # Линейная функция 2\n",
    "        out = self.fc3(out)\n",
    "        # Не линейная функция 2\n",
    "        out = self.elu3(out)\n",
    "        out = self.fc4(out)\n",
    "        # Не линейная функция 2\n",
    "        out = self.elu4(out)\n",
    "        # Линейная функция 4 (readout)\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "\n",
    "# Зададим параметры сети ANN\n",
    "input_dim = 28*28\n",
    "hidden_dim1 = 200 #Размерности скрытых слоев это гиперпараметры которые настраиваются во время обучения. 150 было выбрано произвольно\n",
    "hidden_dim2 = 198\n",
    "hidden_dim3 = 180\n",
    "hidden_dim4 = 170\n",
    "output_dim = 10\n",
    "\n",
    "# Создадим экземпляр ANN\n",
    "model = ANNModel(input_dim, hidden_dim1, hidden_dim2, hidden_dim3,hidden_dim4, output_dim)\n",
    "\n",
    "# Зададим loss функцию как кросс энтропию\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD оптимизатор\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 1.0856877565383911  Accuracy: 72.07142639160156 %\n",
      "Iteration: 1000  Loss: 1.0391238927841187  Accuracy: 62.5476188659668 %\n",
      "Iteration: 1500  Loss: 1.10929274559021  Accuracy: 64.28571319580078 %\n",
      "Iteration: 2000  Loss: 1.3917934894561768  Accuracy: 52.761905670166016 %\n",
      "Iteration: 2500  Loss: 0.9901185035705566  Accuracy: 62.71428680419922 %\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train = Variable(images.view(-1, 28*28) *random.randint(1,12))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Обнулим градиенты\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Проведем forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Посчитаем loss функцию \n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Расчитаем градиенты\n",
    "        loss.backward()\n",
    "        \n",
    "        # Обновим параметры сети\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 50 == 0:\n",
    "            # Подсчет точности        \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Работа с тестовым датасетом\n",
    "            for images, labels in test_loader:\n",
    "\n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Проведем Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # Сохраним loss и iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        if count % 500 == 0:\n",
    "            # Выведем Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"ANN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# Визуализация accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"ANN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
